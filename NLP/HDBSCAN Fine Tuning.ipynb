{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "g434Y6rkmgK8"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8chRnTG5mYfR",
    "outputId": "323cbf82-c1ff-4b3d-f9dd-640b2ff86dac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertopic in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.16.4)\n",
      "Requirement already satisfied: hdbscan>=0.8.29 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bertopic) (0.8.39)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bertopic) (1.23.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bertopic) (2.0.1)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bertopic) (5.22.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bertopic) (1.0.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bertopic) (3.2.1)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bertopic) (4.66.5)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bertopic) (0.5.6)\n",
      "Requirement already satisfied: scipy>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (8.4.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.46.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.26.1)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (10.1.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.12.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "\n",
    "!pip install bertopic\n",
    "from bertopic import BERTopic\n",
    "import umap\n",
    "import hdbscan\n",
    "from hdbscan import HDBSCAN\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "#!pip install sentence-transformers # Install the necessary library\n",
    "from sentence_transformers import SentenceTransformer # Import the SentenceTransformer class\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eBCF1Aqgle5Y"
   },
   "source": [
    "### Loading in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGUXfS7qo2hE",
    "outputId": "24a2fb92-a770-4071-e82d-e03cf0c06a29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-RHm_raglQUo"
   },
   "outputs": [],
   "source": [
    "data_2022_long = pd.read_csv('/content/drive/My Drive/UNI/data_2022_long.csv')\n",
    "data_2020_long = pd.read_csv('/content/drive/My Drive/UNI/data_2020_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KWWyxzc4P1Ni"
   },
   "outputs": [],
   "source": [
    "data_2020_long =  pd.read_csv('data_2020_long.csv')\n",
    "data_2022_long =  pd.read_csv('data_2022_long.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OKFPV3VFalNS"
   },
   "source": [
    "## Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jG7PJnHQGkCB"
   },
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tvG4aLDWckIl"
   },
   "outputs": [],
   "source": [
    "# Convert 'timestamp' column to datetime objects\n",
    "data_2022_long['timestamp'] = pd.to_datetime(data_2022_long['timestamp'])\n",
    "data_2020_long['timestamp'] = pd.to_datetime(data_2020_long['timestamp'])\n",
    "\n",
    "# Now you can extract the year\n",
    "data_2022_long['year'] = data_2022_long['timestamp'].dt.year\n",
    "data_2020_long['year'] = data_2020_long['timestamp'].dt.year  # Corrected line\n",
    "data_2022_long['month'] = data_2022_long['timestamp'].dt.month\n",
    "data_2020_long['month'] = data_2020_long['timestamp'].dt.month\n",
    "\n",
    "# Now you can perform the groupby and filter operations\n",
    "#data_2022_text = data_2022_long[data_2022_long['year'] == 2022]\n",
    "#data_2023_text = data_2022_long[data_2022_long['year'] == 2023]\n",
    "#data_2020_text = data_2020_long[data_2020_long['year'] == 2020]\n",
    "# Assuming you have data_2021_long loaded and processed similarly\n",
    "# data_2021_text = data_2021_long[data_2021_long['year'] == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3h3ZrsGbp0ew"
   },
   "outputs": [],
   "source": [
    "# Define the total sample size and the number of samples to take\n",
    "total_sample_size = 23000\n",
    "\n",
    "# Calculate the number of unique combinations of 'time' and 'subreddit_id'\n",
    "strata = data_2022_long.groupby(['month', 'subreddit_id']).size().reset_index(name='counts')\n",
    "\n",
    "# Calculate the fraction of each stratum to sample based on its size\n",
    "strata['sampling_fraction'] = strata['counts'] / strata['counts'].sum()\n",
    "\n",
    "# Determine how many samples to take from each stratum\n",
    "strata['samples'] = (strata['sampling_fraction'] * total_sample_size).round().astype(int)\n",
    "\n",
    "# Sample from each stratum\n",
    "samples = []\n",
    "for _, row in strata.iterrows():\n",
    "    stratum = data_2022_long[(data_2022_long['month'] == row['month']) & (data_2022_long['subreddit_id'] == row['subreddit_id'])]\n",
    "    sampled_rows = stratum.sample(n=row['samples'], random_state=1)\n",
    "    samples.append(sampled_rows)\n",
    "\n",
    "# Concatenate all samples into a single DataFrame\n",
    "sampled_df_2022 = pd.concat(samples, ignore_index=True)\n",
    "\n",
    "# If the total sampled rows is less than 20,000, you can randomly sample the remaining rows from the entire DataFrame\n",
    "if len(sampled_df_2022) < total_sample_size:\n",
    "    remaining_rows = data_2022_long.sample(n=total_sample_size - len(sampled_df_2022), random_state=1)\n",
    "    sampled_df = pd.concat([sampled_df_2022, remaining_rows], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vhuq2n5cqE6n"
   },
   "outputs": [],
   "source": [
    "# Define the total sample size and the number of samples to take\n",
    "total_sample_size = 33000\n",
    "\n",
    "# Calculate the number of unique combinations of 'time' and 'subreddit_id'\n",
    "strata = data_2020_long.groupby(['month', 'subreddit_id']).size().reset_index(name='counts')\n",
    "\n",
    "# Calculate the fraction of each stratum to sample based on its size\n",
    "strata['sampling_fraction'] = strata['counts'] / strata['counts'].sum()\n",
    "\n",
    "# Determine how many samples to take from each stratum\n",
    "strata['samples'] = (strata['sampling_fraction'] * total_sample_size).round().astype(int)\n",
    "\n",
    "# Sample from each stratum\n",
    "samples = []\n",
    "for _, row in strata.iterrows():\n",
    "    stratum = data_2020_long[(data_2020_long['month'] == row['month']) & (data_2020_long['subreddit_id'] == row['subreddit_id'])]\n",
    "    sampled_rows = stratum.sample(n=row['samples'], random_state=1)\n",
    "    samples.append(sampled_rows)\n",
    "\n",
    "# Concatenate all samples into a single DataFrame\n",
    "sampled_df_2020 = pd.concat(samples, ignore_index=True)\n",
    "\n",
    "# If the total sampled rows is less than 20,000, you can randomly sample the remaining rows from the entire DataFrame\n",
    "if len(data_2020_long) < total_sample_size:\n",
    "    remaining_rows = data_2020_long.sample(n=total_sample_size - len(sampled_df_2020), random_state=1)\n",
    "    sampled_df = pd.concat([sampled_df_2020, remaining_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fSv7POfp71t",
    "outputId": "5d8e7897-d057-48fc-fc62-19b963d731d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024529388809395498"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "33000/1345325 #Sampling about 2.5% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "c-KSbDdsqMj2"
   },
   "outputs": [],
   "source": [
    "sample_data = pd.concat([sampled_df_2020, sampled_df_2022], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Gc1M8PiArICY"
   },
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c53d5b50bedf497cb653e38d59cf599d",
      "b083882ba0d64f5a97449e1f111d8732",
      "1f89fbb380354989aa774f87a65bf558",
      "5740ecbb6d3245a59b24e0b37b5f82cf",
      "9a28f3384de84d5a859309e17d7cd850",
      "ecba33661baa4e6984f5f560be016fe8",
      "7f084ca570e345158b4961de183a0917",
      "0814931d90024868a48c1a5ce96b3f93",
      "ea5078b18c684efba17384f5aa501157",
      "f71efa3e8631423ca6b0c6534482469d",
      "e4c12db54765494b9fb63d501d2d128f"
     ]
    },
    "id": "ycbv0cIVAsvC",
    "outputId": "45958a10-e4ff-47c2-fb71-3f72e8d71e70"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1bebca6a0d40b68180d99213fac272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#step 1 - generate embeddings\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Use an SBERT model for embedding\n",
    "embeddings = model.encode(sample_data['text'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "b9yQlvE-eD-d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Reduce Dimensionality with UMAP\n",
    "fitted_umap = umap.UMAP(n_components=5, n_neighbors=30, min_dist=0.0, random_state=42).fit(embeddings)\n",
    "umap_embeddings = fitted_umap.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "p32B5dopTk0s"
   },
   "outputs": [],
   "source": [
    "#Step 3: Define the parameter range of values\n",
    "min_cluster_sizes = [250, 300, 350, 400]\n",
    "min_samples_values = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "-u21fdmZAfkk"
   },
   "outputs": [],
   "source": [
    "# Step 4: Define a custom HDBSCAN estimator wrapper\n",
    "class HDBSCANWrapper(BaseEstimator, ClusterMixin):\n",
    "    def __init__(self, min_cluster_size=5, min_samples=5, metric='euclidean'):\n",
    "        self.min_cluster_size = min_cluster_size\n",
    "        self.min_samples = min_samples\n",
    "        self.metric = metric\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Instantiate and fit HDBSCAN with the parameters\n",
    "        self.model = HDBSCAN(\n",
    "            min_cluster_size=self.min_cluster_size,\n",
    "            min_samples=self.min_samples,\n",
    "            metric=self.metric,\n",
    "            cluster_selection_method='eom',\n",
    "            gen_min_span_tree=True  # Ensures minimum spanning tree generation\n",
    "        )\n",
    "        self.model.fit(X)\n",
    "        return self\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        # Calculate and return DBCV score as a performance measure\n",
    "        if len(set(self.model.labels_)) > 1:  # Ensure it has more than one cluster\n",
    "            return self.model.relative_validity_\n",
    "        else:\n",
    "            return -np.inf  # Assign a very low score if there's only noise\n",
    "\n",
    "# Step 5: Define parameter distributions for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'min_cluster_size': min_cluster_sizes,\n",
    "    'min_samples': min_samples_values,\n",
    "}\n",
    "\n",
    "# Step 6: Set up RandomizedSearchCV with the custom HDBSCANWrapper\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=HDBSCANWrapper(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Set the number of random configurations to try\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "5l_imoPFBAcB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Perform the search on embeddings\n",
    "search_results = random_search.fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "A0f9cIZeBCSM"
   },
   "outputs": [],
   "source": [
    "# Step 8: Extract the best parameters and score\n",
    "best_model = search_results.best_estimator_\n",
    "best_params = search_results.best_params_\n",
    "best_score = search_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ce13whD9G4U2",
    "outputId": "d3c69a6e-77e3-411e-f9ed-57ee916b2934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples': 5, 'min_cluster_size': 350}\n",
      "Best DBCV Score: 0.18316611700521318\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best DBCV Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Parameters: min samples = 5, min cluster size = 300/350 - HDBSCAN clustering is stochastic in nature"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0814931d90024868a48c1a5ce96b3f93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f89fbb380354989aa774f87a65bf558": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0814931d90024868a48c1a5ce96b3f93",
      "max": 1750,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ea5078b18c684efba17384f5aa501157",
      "value": 1750
     }
    },
    "5740ecbb6d3245a59b24e0b37b5f82cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f71efa3e8631423ca6b0c6534482469d",
      "placeholder": "​",
      "style": "IPY_MODEL_e4c12db54765494b9fb63d501d2d128f",
      "value": " 1750/1750 [21:58&lt;00:00,  4.97it/s]"
     }
    },
    "7f084ca570e345158b4961de183a0917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a28f3384de84d5a859309e17d7cd850": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b083882ba0d64f5a97449e1f111d8732": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecba33661baa4e6984f5f560be016fe8",
      "placeholder": "​",
      "style": "IPY_MODEL_7f084ca570e345158b4961de183a0917",
      "value": "Batches: 100%"
     }
    },
    "c53d5b50bedf497cb653e38d59cf599d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b083882ba0d64f5a97449e1f111d8732",
       "IPY_MODEL_1f89fbb380354989aa774f87a65bf558",
       "IPY_MODEL_5740ecbb6d3245a59b24e0b37b5f82cf"
      ],
      "layout": "IPY_MODEL_9a28f3384de84d5a859309e17d7cd850"
     }
    },
    "e4c12db54765494b9fb63d501d2d128f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea5078b18c684efba17384f5aa501157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ecba33661baa4e6984f5f560be016fe8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f71efa3e8631423ca6b0c6534482469d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
