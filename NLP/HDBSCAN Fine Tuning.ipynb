{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMFCaQlv/AERUnVtTFUz+S7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Import libraries"],"metadata":{"id":"g434Y6rkmgK8"}},{"cell_type":"code","source":["import pandas as pd\n","import warnings\n","import gensim\n","import numpy as np\n","import plotly.express as px\n","import sklearn\n","\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","import string\n","import re\n","import spacy\n","\n","import matplotlib.pyplot as plt\n","\n","!pip install bertopic\n","from bertopic import BERTopic\n","\n","warnings.simplefilter('ignore')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8chRnTG5mYfR","executionInfo":{"status":"ok","timestamp":1730556734604,"user_tz":-480,"elapsed":72328,"user":{"displayName":"Jessica Widyawati","userId":"04280305213402302223"}},"outputId":"3f186ff5-a9b9-4c36-84bc-c7c42e5100a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bertopic\n","  Downloading bertopic-0.16.4-py3-none-any.whl.metadata (23 kB)\n","Collecting hdbscan>=0.8.29 (from bertopic)\n","  Downloading hdbscan-0.8.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.26.4)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.2.2)\n","Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.24.1)\n","Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.5.2)\n","Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (3.2.1)\n","Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.6)\n","Collecting umap-learn>=0.5.0 (from bertopic)\n","  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.13.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (9.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (24.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.5.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.44.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.5.0+cu121)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.24.7)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (10.4.0)\n","Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n","Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n","  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.10.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.12.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.19.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.8.30)\n","Downloading bertopic-0.16.4-py3-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hdbscan-0.8.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pynndescent, hdbscan, umap-learn, bertopic\n","Successfully installed bertopic-0.16.4 hdbscan-0.8.39 pynndescent-0.5.13 umap-learn-0.5.7\n"]}]},{"cell_type":"markdown","source":["### Loading in datasets"],"metadata":{"id":"eBCF1Aqgle5Y"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGUXfS7qo2hE","executionInfo":{"status":"ok","timestamp":1730556762356,"user_tz":-480,"elapsed":27756,"user":{"displayName":"Jessica Widyawati","userId":"04280305213402302223"}},"outputId":"31d3f32b-0ce1-48c0-aaae-c3645cb2f930"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_2020_long = pd.read_csv('/content/drive/My Drive/UNI/data_2020_long.csv')\n","data_2022 = pd.read_csv('/content/drive/My Drive/UNI/data_2022.csv')"],"metadata":{"id":"-RHm_raglQUo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_2022['timestamp'] = pd.to_datetime(data_2022['timestamp'])\n","data_2022['comment_length'] = data_2022['text'].str.split(' ').str.len()\n","data_2022['text'] = data_2022['text'].astype(str)\n","data_2022.drop(data_2022.columns[0], axis=1, inplace=True)\n","\n","# Dataset before filtering for longer\n","data_2022.shape"],"metadata":{"id":"3OWT0G3kmxsG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730556859633,"user_tz":-480,"elapsed":14299,"user":{"displayName":"Jessica Widyawati","userId":"04280305213402302223"}},"outputId":"ab96e44b-831a-4d54-d805-45f5853d629b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1823746, 11)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["data_2022_long = data_2022[data_2022['comment_length'] > 8]\n","data_2022_long.shape #about 50% of the dataset has comments longer than 8"],"metadata":{"id":"wcae2q36m4aB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730556860621,"user_tz":-480,"elapsed":387,"user":{"displayName":"Jessica Widyawati","userId":"04280305213402302223"}},"outputId":"e0caaac4-b3a1-4407-b264-f20c4efb2317"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(922522, 11)"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["##Random Sampling"],"metadata":{"id":"OKFPV3VFalNS"}},{"source":["data_2022_long['year'] = data_2022_long['timestamp'].dt.year\n","data_2020_long['year'] = data_2022_long['timestamp'].dt.year\n","\n","# Now you can perform the groupby and filter operations\n","data_2022_text = data_2022_long[data_2022_long['year'] == 2022]\n","data_2023_text = data_2022_long[data_2022_long['year'] == 2023]\n","data_2020_text = data_2020_long[data_2020_long['year'] == 2020]\n","data_2021_text = data_2021_long[data_2021_long['year'] == 2021]"],"cell_type":"code","metadata":{"id":"tvG4aLDWckIl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_2022_long['month'] = data_2022_long['timestamp'].dt.month"],"metadata":{"id":"WpUWP_kNmAY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["23000/922522 #Sampling about 2.5% of the data"],"metadata":{"id":"nhQdOVU1pziv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the total sample size and the number of samples to take\n","total_sample_size = 23000\n","\n","# Calculate the number of unique combinations of 'time' and 'subreddit_id'\n","strata = data_2022_long.groupby(['month', 'subreddit_id']).size().reset_index(name='counts')\n","\n","# Calculate the fraction of each stratum to sample based on its size\n","strata['sampling_fraction'] = strata['counts'] / strata['counts'].sum()\n","\n","# Determine how many samples to take from each stratum\n","strata['samples'] = (strata['sampling_fraction'] * total_sample_size).round().astype(int)\n","\n","# Sample from each stratum\n","samples = []\n","for _, row in strata.iterrows():\n","    stratum = data_2022_long[(data_2022_long['month'] == row['month']) & (data_2022_long['subreddit_id'] == row['subreddit_id'])]\n","    sampled_rows = stratum.sample(n=row['samples'], random_state=1)\n","    samples.append(sampled_rows)\n","\n","# Concatenate all samples into a single DataFrame\n","sampled_df_2022 = pd.concat(samples, ignore_index=True)\n","\n","# If the total sampled rows is less than 20,000, you can randomly sample the remaining rows from the entire DataFrame\n","if len(sampled_df_2022) < total_sample_size:\n","    remaining_rows = data_2022_long.sample(n=total_sample_size - len(sampled_df_2022), random_state=1)\n","    sampled_df = pd.concat([sampled_df_2022, remaining_rows], ignore_index=True)\n"],"metadata":{"id":"3h3ZrsGbp0ew"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_2020_long['timestamp'] = pd.to_datetime(data_2020_long['timestamp'])\n","data_2020_long['month'] = data_2020_long['timestamp'].dt.month"],"metadata":{"id":"0XogyjUZp4_F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["33000/1345325 #Sampling about 2.5% of the data"],"metadata":{"id":"9fSv7POfp71t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the total sample size and the number of samples to take\n","total_sample_size = 33000\n","\n","# Calculate the number of unique combinations of 'time' and 'subreddit_id'\n","strata = data_2020_long.groupby(['month', 'subreddit_id']).size().reset_index(name='counts')\n","\n","# Calculate the fraction of each stratum to sample based on its size\n","strata['sampling_fraction'] = strata['counts'] / strata['counts'].sum()\n","\n","# Determine how many samples to take from each stratum\n","strata['samples'] = (strata['sampling_fraction'] * total_sample_size).round().astype(int)\n","\n","# Sample from each stratum\n","samples = []\n","for _, row in strata.iterrows():\n","    stratum = data_2020_long[(data_2020_long['month'] == row['month']) & (data_2020_long['subreddit_id'] == row['subreddit_id'])]\n","    sampled_rows = stratum.sample(n=row['samples'], random_state=1)\n","    samples.append(sampled_rows)\n","\n","# Concatenate all samples into a single DataFrame\n","sampled_df_2020 = pd.concat(samples, ignore_index=True)\n","\n","# If the total sampled rows is less than 20,000, you can randomly sample the remaining rows from the entire DataFrame\n","if len(data_2020_long) < total_sample_size:\n","    remaining_rows = data_2020_long.sample(n=total_sample_size - len(sampled_df_2020), random_state=1)\n","    sampled_df = pd.concat([sampled_df_2020, remaining_rows], ignore_index=True)"],"metadata":{"id":"vhuq2n5cqE6n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_data = pd.concat([sampled_df_2020, sampled_df_2022], ignore_index=True)"],"metadata":{"id":"c-KSbDdsqMj2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Generating Embeddings for 2020-2021 dataset and 2022-2023 dataset"],"metadata":{"id":"7BE0qbKHz05J"}},{"cell_type":"code","source":["# Step 1: Convert Text Data to Embeddings\n","model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Use an SBERT model for embedding\n","embeddings_2020 = model.encode(data_2020_long['text'].tolist(), show_progress_bar=True)\n","embeddings_2022 = model.encode(data_2022_long['text'].tolist(), show_progress_bar=True)"],"metadata":{"id":"G9XeridLzzmc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save the embeddings as separate files\n","np.save(\"/content/drive/My Drive/UNI/flattened_embeddings_2020.npy\", embeddings_2020)\n","np.save(\"/content/drive/My Drive/UNI/flattened_embeddings_2022.npy\", embeddings_2022)"],"metadata":{"id":"xvCXBUFa06MZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tuning"],"metadata":{"id":"Gc1M8PiArICY"}},{"cell_type":"code","source":["SEED = 42"],"metadata":{"id":"33xUnBzVAzRn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#step 1 - generate embeddings\n","model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Use an SBERT model for embedding\n","embeddings = model.encode(sample_data['text'].tolist(), show_progress_bar=True)"],"metadata":{"id":"ycbv0cIVAsvC","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1730520897978,"user_tz":-480,"elapsed":2097,"user":{"displayName":"Jessica Widyawati","userId":"04280305213402302223"}},"outputId":"2cf8eee7-54a1-4eec-8d7e-5555fa4f8300"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"cannot reshape array of size 322699232 into shape (1345325,384)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-850166a33249>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 1: load embeddings from 2022 and 2020 datasests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membeddings_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flattened_embeddings_2020.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0membeddings_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flattened_embeddings_2022.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    454\u001b[0m                                           max_header_size=max_header_size)\n\u001b[1;32m    455\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    457\u001b[0m                                          \u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                                          max_header_size=max_header_size)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 322699232 into shape (1345325,384)"]}]},{"cell_type":"code","source":["# Step 2: Reduce Dimensionality with UMAP\n","fitted_umap = umap.UMAP(n_components=5, n_neighbors=30, min_dist=0.0, random_state=SEED).fit(embeddings)\n","umap_embeddings = fitted_umap.embedding_"],"metadata":{"id":"8qn3A_SFAqJP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 3: Define DBCV Score Function for RandomizedSearchCV\n","def calculate_core_distances(X, min_samples):\n","    from sklearn.metrics import pairwise_distances\n","    distances = pairwise_distances(X)\n","    sorted_distances = np.sort(distances, axis=1)\n","    core_distances = sorted_distances[:, min_samples]\n","    return core_distances"],"metadata":{"id":"UF2u8T81Allq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-u21fdmZAfkk"},"outputs":[],"source":["def calculate_density_reachable(X, labels, core_distances):\n","    density_reachable = np.zeros((X.shape[0], X.shape[0]))\n","    for i in range(X.shape[0]):\n","        for j in range(i + 1, X.shape[0]):\n","            if labels[i] == labels[j] and labels[i] != -1:\n","                distance = np.linalg.norm(X[i] - X[j])\n","                reachable = max(core_distances[i], core_distances[j])\n","                if distance <= reachable:\n","                    density_reachable[i, j] = density_reachable[j, i] = 1\n","    return density_reachable"]},{"cell_type":"code","source":["def dbcv_score(X, labels, min_samples):\n","    core_distances = calculate_core_distances(X, min_samples)\n","    density_reachable = calculate_density_reachable(X, labels, core_distances)\n","    total_reachability = np.sum(density_reachable)\n","\n","    clusters = np.unique(labels)\n","    clusters = clusters[clusters != -1]\n","\n","    cluster_validity = []\n","    for cluster in clusters:\n","        cluster_points = X[labels == cluster]\n","        if len(cluster_points) > 1:\n","            intra_cluster_density = np.mean([\n","                np.sum(density_reachable[labels == cluster][:, labels == cluster]) / 2\n","            ])\n","            cluster_validity.append(intra_cluster_density)\n","    if cluster_validity:\n","        validity_index = np.mean(cluster_validity) / total_reachability\n","    else:\n","        validity_index = -1\n","    return validity_index"],"metadata":{"id":"5l_imoPFBAcB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def custom_dbcv_scorer(estimator, X):\n","    labels = estimator.fit_predict(X)\n","    if len(np.unique(labels)) > 1:\n","        return dbcv_score(X, labels, estimator.min_samples)\n","    else:\n","        return -1  # Penalize configurations with no valid clusters"],"metadata":{"id":"A0f9cIZeBCSM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dbcv_scorer = make_scorer(custom_dbcv_scorer, greater_is_better=True)"],"metadata":{"id":"zDaR8RZsBF99"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#set up parameter distribution\n","# Step 4: Set up Parameter Distributions for RandomizedSearchCV\n","param_distributions = {\n","    \"min_samples\": [5, 10, 15, 20],\n","    \"min_cluster_size\": [250, 300, 350, 400],\n","    \"cluster_selection_method\": [\"eom\", \"leaf\"],\n","    \"metric\": [\"euclidean\", \"manhattan\"],\n","}"],"metadata":{"id":"-eEZ7BBQGVXk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 5: Initialize HDBSCAN and RandomizedSearchCV\n","hdb = hdbscan.HDBSCAN()\n","random_search = RandomizedSearchCV(\n","    hdb,\n","    param_distributions=param_distributions,\n","    n_iter=50,\n","    scoring=dbcv_scorer,\n","    random_state=SEED,\n",")"],"metadata":{"id":"nnnPP0sIG0Z5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: Fit RandomizedSearchCV on UMAP Embeddings\n","random_search.fit(umap_embeddings)"],"metadata":{"id":"Do-oNaAyG2U6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get Best Parameters and Score\n","print(f\"Best Parameters: {random_search.best_params_}\")\n","print(f\"Best DBCV Score: {random_search.best_score_}\")"],"metadata":{"id":"Ce13whD9G4U2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 7: Use Best HDBSCAN Model in BERTopic\n","best_hdbscan = random_search.best_estimator_"],"metadata":{"id":"VrYW_Lf_G6DP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#best parameters are: min_samples = 5, min_cluster_size = 300, cluster_selection_method = \"eom\", metric = \"euclidean\""],"metadata":{"id":"QuujtcQR1wby"},"execution_count":null,"outputs":[]}]}